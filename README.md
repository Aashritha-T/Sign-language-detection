# ğŸ–ï¸ Sign Language Detection Using Machine Learning
A machine learning project that identifies American Sign Language (ASL) alphabets (Aâ€“Z) from hand gesture images. Designed with the vision to bridge the communication gap between the speech/hearing impaired and the rest of the world through computer vision and AI.

## ğŸ“Œ Table of Contents

- [ğŸ“Œ Table of Contents](#-table-of-contents)
- [ğŸš€ Project Overview](#-project-overview)
- [ğŸ“‚ Dataset](#-dataset)
- [ğŸ› ï¸ Tech Stack](#ï¸-tech-stack)
- [ğŸ“ˆ Model Training & Evaluation](#-model-training--evaluation)
- [ğŸ’» How to Run Locally](#-how-to-run-locally)
- [ğŸ§  Future Scope](#-future-scope)
- [ğŸ™Œ Acknowledgements](#-acknowledgements)
- [ğŸ‘©â€ğŸ’» Author](#-author)

## ğŸš€ Project Overview

This project uses machine learning and image classification techniques to recognize static hand gestures representing the 26 English alphabets in ASL. It helps translate visual signs into textual output, promoting inclusivity and accessibility.

> ğŸ§  **Why this matters:**  
> Communication barriers can isolate individuals with hearing impairments. This project is a step toward building assistive tech that empowers communication for all.

## ğŸ“‚ Dataset

- The dataset consists of **thousands of labeled images** representing the alphabets A to Z.
- Each class (Aâ€“Z) contains images of hand gestures in varying lighting, angles, and skin tones to ensure model robustness.
- Preprocessing includes:
  - Grayscale conversion
  - Resizing (e.g., 64x64 or 128x128)
  - Normalization
---

##  Sample Output

Hand gesture - alphabet-accuracy

## ğŸ› ï¸ Tech Stack

- Language: Python  
- Libraries/Frameworks:
  - Scikit-learn / TensorFlow / Keras  
  - NumPy, Pandas  
  - OpenCV (for image preprocessing)  
  - Matplotlib / Seaborn (for visualization)  

## ğŸ“ˆ Model Training & Evaluation

- **Model Used:** [e.g., CNN, SVM, Random Forest]  
- **Training Accuracy:** ~[85]%  
- **Testing Accuracy:** ~[80]%  
- **Confusion Matrix & Classification Report** to evaluate per-class performance.

## ğŸ’» How to Run Locally

### ğŸ”§ Prerequisites

Make sure Python 3.7+ is installed.

```bash
pip install -r requirements.txt
````

### ğŸš¦ Training the Model

```bash
python train.py
```

### ğŸ“¤ Predicting on Test Images

```bash
python predict.py --image path_to_image.jpg
```

### ğŸ¥ (Optional) Real-time Webcam Detection

```bash
python realtime_detection.py
```

---

## ğŸ§  Future Scope

* âœ¨ Add dynamic gestures (words/sentences)
* ğŸŒ Build a web app or mobile app for real-time detection
* ğŸ“± Integrate with voice assistant or text-to-speech
* ğŸ‡®ğŸ‡³ Extend support to Indian or other regional sign languages.

## ğŸ‘©â€ğŸ’» Author

**Aashritha Thirunahari**
Aspiring ML Developer | Passionate about AI for social good
[GitHub](https://github.com/Aahritha-T) | [LinkedIn](https://linkedin.com/in/thiruaashritha)

> ğŸ’¬ *â€œTechnology is most powerful when it empowers everyone.â€*
> â€” Tim Cook

â­ If you found this project interesting, give it a star!
ğŸ“¬ Feel free to open issues or contribute with pull requests.

